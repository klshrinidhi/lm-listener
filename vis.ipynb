{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import pickle\n",
    "from itertools import chain\n",
    "\n",
    "from yacs.config import CfgNode\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import trimesh\n",
    "\n",
    "deca_d = '/vision/changan/shrinidhi/DECA'\n",
    "sys.path.append(deca_d)\n",
    "\n",
    "from decalib.models.FLAME import FLAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d = pathlib.Path('/vision/vision_data_2/VGGSound_shards_fixed/shrinidhi/lm_listener/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26832"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_segs = [torch.load(f)\n",
    "              for f in data_d.glob('*/segments_train.pth')]\n",
    "train_segs = list(chain(*train_segs))\n",
    "len(train_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2840"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_segs = [torch.load(f)\n",
    "              for f in data_d.glob('*/segments_val.pth')]\n",
    "val_segs = list(chain(*val_segs))\n",
    "len(val_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8534"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_segs = [torch.load(f)\n",
    "              for f in data_d.glob('*/segments_test.pth')]\n",
    "test_segs = list(chain(*test_segs))\n",
    "len(test_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 207.942\n",
      "end 267.95\n",
      "speaker SPEAKER_00\n",
      "split_start_frame 7236\n",
      "split_end_frame 7922\n",
      "split_start_time 241.2\n",
      "split_end_time 264.06666666666666\n",
      "fname conan_videos/done_conan_videos0/079YouTube/079YouTube.mp4\n",
      "before_words [{'text': 'Well,', 'start': 208.46, 'end': 209.5, 'confidence': 0.998}, {'text': 'I', 'start': 209.5, 'end': 209.7, 'confidence': 0.987}, {'text': \"don't\", 'start': 209.7, 'end': 209.96, 'confidence': 0.838}, {'text': 'know.', 'start': 209.96, 'end': 210.43, 'confidence': 0.984}, {'text': 'I', 'start': 210.43, 'end': 210.47, 'confidence': 1.0}, {'text': 'think', 'start': 210.47, 'end': 210.54, 'confidence': 1.0}, {'text': 'Ted', 'start': 210.54, 'end': 210.74, 'confidence': 0.995}, {'text': 'Sarandos', 'start': 210.74, 'end': 211.38, 'confidence': 0.917}, {'text': 'who', 'start': 211.38, 'end': 211.56, 'confidence': 0.722}, {'text': 'runs', 'start': 211.56, 'end': 211.76, 'confidence': 0.999}, {'text': 'Netflix', 'start': 211.76, 'end': 212.18, 'confidence': 0.998}, {'text': 'lost', 'start': 212.3, 'end': 212.54, 'confidence': 0.995}, {'text': 'a', 'start': 212.54, 'end': 212.7, 'confidence': 0.986}, {'text': 'bet', 'start': 212.7, 'end': 212.96, 'confidence': 0.997}, {'text': 'of', 'start': 212.96, 'end': 213.14, 'confidence': 0.997}, {'text': 'some', 'start': 213.14, 'end': 213.36, 'confidence': 1.0}, {'text': 'sort.', 'start': 213.36, 'end': 213.78, 'confidence': 0.998}, {'text': 'No,', 'start': 214.1, 'end': 214.68, 'confidence': 0.997}, {'text': 'it', 'start': 214.68, 'end': 214.76, 'confidence': 0.561}, {'text': 'was', 'start': 214.76, 'end': 215.02, 'confidence': 0.999}, {'text': 'Ted', 'start': 215.02, 'end': 215.38, 'confidence': 0.995}, {'text': 'Sarandos.', 'start': 215.38, 'end': 216.06, 'confidence': 0.99}, {'text': 'I', 'start': 216.18, 'end': 216.8, 'confidence': 1.0}, {'text': 'worked', 'start': 216.8, 'end': 217.12, 'confidence': 0.979}, {'text': 'for', 'start': 217.12, 'end': 217.26, 'confidence': 0.999}, {'text': 'Netflix', 'start': 217.26, 'end': 217.6, 'confidence': 0.999}, {'text': 'a', 'start': 217.6, 'end': 217.76, 'confidence': 0.998}, {'text': 'couple', 'start': 217.76, 'end': 217.94, 'confidence': 1.0}, {'text': 'of', 'start': 217.94, 'end': 218.14, 'confidence': 0.83}, {'text': 'times', 'start': 218.14, 'end': 218.34, 'confidence': 0.999}, {'text': 'and', 'start': 218.82, 'end': 219.0, 'confidence': 1.0}, {'text': 'I', 'start': 219.0, 'end': 219.16, 'confidence': 0.999}, {'text': 'had', 'start': 219.16, 'end': 219.28, 'confidence': 0.999}, {'text': 'a', 'start': 219.28, 'end': 219.36, 'confidence': 0.998}, {'text': 'show', 'start': 219.36, 'end': 219.54, 'confidence': 1.0}, {'text': 'on', 'start': 219.54, 'end': 219.68, 'confidence': 0.973}, {'text': 'there', 'start': 219.68, 'end': 219.82, 'confidence': 0.999}, {'text': 'at', 'start': 219.82, 'end': 219.94, 'confidence': 0.993}, {'text': 'one', 'start': 219.94, 'end': 220.08, 'confidence': 0.999}, {'text': 'point', 'start': 220.08, 'end': 220.38, 'confidence': 0.999}, {'text': 'and', 'start': 220.58, 'end': 220.92, 'confidence': 1.0}, {'text': 'he', 'start': 220.92, 'end': 221.28, 'confidence': 1.0}, {'text': 'was', 'start': 221.28, 'end': 221.44, 'confidence': 0.999}, {'text': 'just', 'start': 221.44, 'end': 221.66, 'confidence': 0.999}, {'text': 'very', 'start': 221.66, 'end': 221.9, 'confidence': 0.999}, {'text': 'nice', 'start': 221.9, 'end': 222.5, 'confidence': 1.0}, {'text': 'and', 'start': 222.5, 'end': 223.06, 'confidence': 0.588}, {'text': 'asked', 'start': 223.06, 'end': 223.74, 'confidence': 0.98}, {'text': 'me', 'start': 223.74, 'end': 223.94, 'confidence': 0.999}, {'text': 'if', 'start': 223.94, 'end': 224.1, 'confidence': 0.947}, {'text': 'I', 'start': 224.1, 'end': 224.18, 'confidence': 0.999}, {'text': 'would', 'start': 224.18, 'end': 224.34, 'confidence': 1.0}, {'text': 'do', 'start': 224.34, 'end': 224.52, 'confidence': 0.999}, {'text': 'it.', 'start': 224.52, 'end': 224.8, 'confidence': 1.0}, {'text': 'And', 'start': 225.26, 'end': 225.56, 'confidence': 0.941}, {'text': 'to', 'start': 225.56, 'end': 225.62, 'confidence': 0.948}, {'text': 'which', 'start': 225.62, 'end': 225.94, 'confidence': 0.997}, {'text': 'I', 'start': 225.94, 'end': 226.26, 'confidence': 0.981}, {'text': 'did,', 'start': 226.26, 'end': 227.46, 'confidence': 0.825}, {'text': 'I', 'start': 227.46, 'end': 227.8, 'confidence': 0.807}, {'text': 'looked', 'start': 227.8, 'end': 228.04, 'confidence': 0.961}, {'text': 'like', 'start': 228.04, 'end': 228.36, 'confidence': 0.973}, {'text': 'it', 'start': 228.36, 'end': 228.78, 'confidence': 0.703}, {'text': 'was', 'start': 228.78, 'end': 228.94, 'confidence': 0.998}, {'text': 'a', 'start': 228.94, 'end': 229.04, 'confidence': 0.981}, {'text': 'Lucy', 'start': 229.04, 'end': 229.28, 'confidence': 0.83}, {'text': 'sketch', 'start': 229.28, 'end': 229.66, 'confidence': 0.963}, {'text': 'saying', 'start': 230.08, 'end': 230.34, 'confidence': 1.0}, {'text': 'yes', 'start': 230.34, 'end': 230.88, 'confidence': 0.92}, {'text': 'and', 'start': 230.88, 'end': 231.2, 'confidence': 0.332}, {'text': 'I,', 'start': 231.2, 'end': 231.92, 'confidence': 0.65}, {'text': 'because', 'start': 231.92, 'end': 231.96, 'confidence': 0.324}, {'text': 'I', 'start': 231.96, 'end': 233.24, 'confidence': 0.985}, {'text': 'liked', 'start': 233.24, 'end': 233.98, 'confidence': 0.624}, {'text': 'the', 'start': 233.98, 'end': 234.28, 'confidence': 0.988}, {'text': 'series', 'start': 234.28, 'end': 234.69, 'confidence': 0.995}, {'text': 'and', 'start': 234.69, 'end': 235.08, 'confidence': 0.999}, {'text': 'to', 'start': 235.08, 'end': 235.16, 'confidence': 0.974}, {'text': 'be,', 'start': 235.16, 'end': 235.74, 'confidence': 0.53}, {'text': 'to', 'start': 235.74, 'end': 235.88, 'confidence': 0.814}, {'text': 'just', 'start': 235.88, 'end': 236.02, 'confidence': 0.996}, {'text': 'have', 'start': 236.02, 'end': 236.32, 'confidence': 0.996}, {'text': 'a', 'start': 236.32, 'end': 236.52, 'confidence': 0.999}, {'text': 'tiny', 'start': 236.52, 'end': 236.74, 'confidence': 0.998}, {'text': 'little', 'start': 236.74, 'end': 236.94, 'confidence': 0.996}, {'text': 'part', 'start': 236.94, 'end': 237.22, 'confidence': 0.996}, {'text': 'in', 'start': 237.22, 'end': 237.44, 'confidence': 0.953}, {'text': 'it', 'start': 237.44, 'end': 237.74, 'confidence': 0.998}, {'text': 'and', 'start': 238.06, 'end': 238.5, 'confidence': 1.0}, {'text': 'interview', 'start': 238.5, 'end': 239.02, 'confidence': 0.992}, {'text': 'some', 'start': 239.02, 'end': 239.38, 'confidence': 0.998}, {'text': 'of', 'start': 239.38, 'end': 239.5, 'confidence': 0.999}, {'text': 'these', 'start': 239.5, 'end': 239.7, 'confidence': 0.999}, {'text': 'people', 'start': 239.7, 'end': 239.88, 'confidence': 0.999}, {'text': 'was', 'start': 239.88, 'end': 240.34, 'confidence': 0.992}, {'text': 'really', 'start': 240.34, 'end': 240.66, 'confidence': 1.0}]\n",
      "during_words [{'text': 'fun.', 'start': 240.66, 'end': 241.28, 'confidence': 1.0}, {'text': 'And', 'start': 241.4, 'end': 241.52, 'confidence': 0.997}, {'text': 'then', 'start': 241.52, 'end': 241.7, 'confidence': 0.999}, {'text': 'people', 'start': 241.7, 'end': 241.96, 'confidence': 0.999}, {'text': 'gave', 'start': 241.96, 'end': 242.3, 'confidence': 0.999}, {'text': 'me', 'start': 242.3, 'end': 242.7, 'confidence': 0.998}, {'text': 'such', 'start': 242.7, 'end': 243.1, 'confidence': 0.999}, {'text': 'shit', 'start': 243.1, 'end': 243.78, 'confidence': 0.949}, {'text': 'for', 'start': 244.38, 'end': 244.64, 'confidence': 1.0}, {'text': 'asking', 'start': 244.64, 'end': 245.12, 'confidence': 1.0}, {'text': 'if', 'start': 245.12, 'end': 245.34, 'confidence': 0.982}, {'text': 'Joe', 'start': 245.34, 'end': 245.62, 'confidence': 0.99}, {'text': 'Exotic', 'start': 245.62, 'end': 246.0, 'confidence': 0.923}, {'text': 'should', 'start': 246.0, 'end': 246.2, 'confidence': 0.996}, {'text': 'be', 'start': 246.2, 'end': 246.4, 'confidence': 1.0}, {'text': 'in', 'start': 246.4, 'end': 246.54, 'confidence': 0.998}, {'text': 'jail.', 'start': 246.54, 'end': 247.06, 'confidence': 1.0}, {'text': 'And', 'start': 247.52, 'end': 247.84, 'confidence': 0.996}, {'text': 'I', 'start': 247.84, 'end': 247.94, 'confidence': 1.0}, {'text': 'was', 'start': 247.94, 'end': 248.08, 'confidence': 1.0}, {'text': 'like,', 'start': 248.08, 'end': 248.26, 'confidence': 0.997}, {'text': 'that', 'start': 248.26, 'end': 248.38, 'confidence': 0.879}, {'text': \"doesn't\", 'start': 248.38, 'end': 248.66, 'confidence': 0.998}, {'text': 'seem', 'start': 248.66, 'end': 249.04, 'confidence': 0.998}, {'text': 'like', 'start': 249.18, 'end': 249.52, 'confidence': 1.0}, {'text': 'a', 'start': 249.52, 'end': 249.78, 'confidence': 0.997}, {'text': 'real', 'start': 249.78, 'end': 250.18, 'confidence': 0.994}, {'text': 'hard', 'start': 250.18, 'end': 250.56, 'confidence': 0.991}, {'text': 'hitting', 'start': 250.56, 'end': 251.16, 'confidence': 0.747}, {'text': 'gotcha', 'start': 251.16, 'end': 251.86, 'confidence': 0.786}, {'text': 'question.', 'start': 251.86, 'end': 252.32, 'confidence': 0.945}, {'text': 'They', 'start': 252.32, 'end': 252.5, 'confidence': 0.628}, {'text': 'thought', 'start': 252.5, 'end': 252.56, 'confidence': 0.993}, {'text': 'that', 'start': 252.56, 'end': 252.64, 'confidence': 0.984}, {'text': 'was', 'start': 252.64, 'end': 252.82, 'confidence': 0.981}, {'text': 'a', 'start': 252.82, 'end': 252.92, 'confidence': 0.995}, {'text': 'rude', 'start': 252.92, 'end': 253.36, 'confidence': 0.997}, {'text': 'question.', 'start': 253.36, 'end': 253.86, 'confidence': 0.999}, {'text': 'They', 'start': 254.04, 'end': 254.16, 'confidence': 0.995}, {'text': 'were', 'start': 254.16, 'end': 254.32, 'confidence': 0.983}, {'text': 'like,', 'start': 254.32, 'end': 254.52, 'confidence': 0.999}, {'text': 'how', 'start': 254.52, 'end': 254.58, 'confidence': 0.988}, {'text': 'dare', 'start': 254.58, 'end': 254.88, 'confidence': 0.999}, {'text': 'you?', 'start': 254.88, 'end': 255.26, 'confidence': 0.999}, {'text': 'How', 'start': 255.4, 'end': 255.58, 'confidence': 0.995}, {'text': 'dare', 'start': 255.58, 'end': 255.84, 'confidence': 0.999}, {'text': 'you?', 'start': 255.84, 'end': 256.14, 'confidence': 0.999}, {'text': 'And', 'start': 256.18, 'end': 256.58, 'confidence': 0.996}, {'text': 'I', 'start': 256.58, 'end': 256.72, 'confidence': 0.998}, {'text': 'was', 'start': 256.72, 'end': 257.0, 'confidence': 0.997}, {'text': 'like,', 'start': 257.0, 'end': 257.08, 'confidence': 0.98}, {'text': '19', 'start': 257.08, 'end': 257.72, 'confidence': 0.81}, {'text': 'felonies?', 'start': 257.72, 'end': 258.38, 'confidence': 0.997}, {'text': 'Animal', 'start': 260.36, 'end': 260.54, 'confidence': 0.99}, {'text': 'abuse?', 'start': 260.54, 'end': 261.17, 'confidence': 0.993}, {'text': 'And', 'start': 261.17, 'end': 261.62, 'confidence': 0.99}, {'text': 'they,', 'start': 261.62, 'end': 262.06, 'confidence': 0.492}, {'text': 'it', 'start': 262.06, 'end': 262.3, 'confidence': 0.991}, {'text': 'was', 'start': 262.3, 'end': 262.46, 'confidence': 1.0}, {'text': 'a', 'start': 262.46, 'end': 262.56, 'confidence': 0.995}, {'text': 'weird', 'start': 262.56, 'end': 262.86, 'confidence': 1.0}, {'text': 'thing', 'start': 262.86, 'end': 263.08, 'confidence': 0.999}, {'text': 'because', 'start': 263.1, 'end': 263.32, 'confidence': 1.0}, {'text': 'I', 'start': 263.32, 'end': 263.48, 'confidence': 0.998}, {'text': 'think', 'start': 263.48, 'end': 263.7, 'confidence': 1.0}]\n",
      "p0_exp torch.Size([687, 50])\n",
      "p0_pose torch.Size([687, 6])\n",
      "p0_shape torch.Size([687, 100])\n",
      "p0_detail torch.Size([687, 128])\n",
      "p1_exp torch.Size([687, 50])\n",
      "p1_pose torch.Size([687, 6])\n",
      "p1_shape torch.Size([687, 100])\n",
      "p1_detail torch.Size([687, 128])\n"
     ]
    }
   ],
   "source": [
    "for k,v in train_segs[0].items():\n",
    "    if isinstance(v,torch.Tensor):\n",
    "        print(k,v.shape)\n",
    "    else:\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f (9976, 3)\n",
      "J_regressor (5, 5023)\n",
      "kintree_table (2, 5)\n",
      "J (5, 3)\n",
      "bs_style lbs\n",
      "weights (5023, 5)\n",
      "posedirs (5023, 3, 36)\n",
      "v_template (5023, 3)\n",
      "shapedirs (5023, 3, 400)\n",
      "bs_type lrotmin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_219956/1564281621.py:1: DeprecationWarning: Please import `csc_matrix` from the `scipy.sparse` namespace; the `scipy.sparse.csc` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  model = pickle.load(open('/vision/changan/shrinidhi/DECA/data/generic_model.pkl','rb'),encoding='latin1')\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('/vision/changan/shrinidhi/DECA/data/generic_model.pkl','rb'),encoding='latin1')\n",
    "for k,v in model.items():\n",
    "    if hasattr(v,'shape'):\n",
    "        print(k,v.shape)\n",
    "    else:\n",
    "        print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating the FLAME Decoder\n"
     ]
    }
   ],
   "source": [
    "cfg = CfgNode({'flame_model_path':f'{deca_d}/data/generic_model.pkl',\n",
    "               'flame_lmk_embedding_path':f'{deca_d}/data/landmark_embedding.npy',\n",
    "               'n_shape':100,\n",
    "               'n_exp':50,\n",
    "               'n_pose':6})\n",
    "flame = FLAME(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = test_segs\n",
    "meshes_d = pathlib.Path('/vision/vision_data_2/VGGSound_shards_fixed/shrinidhi/lm_listener/meshes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41f6b40777b4de79aff1a9f59a5a973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "examples:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i_e,example in enumerate(tqdm(examples[:12],desc='examples')):\n",
    "    ply_d = meshes_d / f'{i_e:05}' / 'p0'\n",
    "    ply_d.mkdir(exist_ok=True,parents=True)\n",
    "    verts,_,_ = flame(shape_params=example['p0_shape'],\n",
    "                      expression_params=example['p0_exp'],\n",
    "                      pose_params=example['p0_pose'])\n",
    "    for i in range(verts.shape[0]):\n",
    "        ply_f = f'{ply_d}/{i:05}.ply'\n",
    "        mesh = trimesh.Trimesh(vertices=verts[i],\n",
    "                                faces=flame.faces_tensor,\n",
    "                                process=False)\n",
    "        mesh.export(ply_f)\n",
    "    # ply_d = meshes_d / f'{i_e:05}' / 'p1'\n",
    "    # ply_d.mkdir(exist_ok=True,parents=True)\n",
    "    # verts,_,_ = flame(shape_params=example['p1_shape'],\n",
    "    #                   expression_params=example['p1_exp'],\n",
    "    #                   pose_params=example['p1_pose'])\n",
    "    # for i in range(verts.shape[0]):\n",
    "    #     ply_f = f'{ply_d}/{i:05}.ply'\n",
    "    #     mesh = trimesh.Trimesh(vertices=verts[i],\n",
    "    #                             faces=flame.faces_tensor,\n",
    "    #                             process=False)\n",
    "    #     mesh.export(ply_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
